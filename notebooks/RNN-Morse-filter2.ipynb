{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with noisy envelope - filter with dual input version\n",
    "\n",
    "Starting from `RNN-Morse-filter` a pure noise channel is added along the noisy signal channel in an attempt for the network to better identify silence periods.\n",
    "\n",
    "The formatting of X data is changed to take into account the second dimensionality of the time series (samples). This shows an example of dealing with 2D time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sounddevice torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate annotated raw signal\n",
    "\n",
    "Generates the envelope after audio preprocessing. The resulting decimation factor is 128 thus we will take 1 every 128 samples from the original signal modulated at 8 kHz sample rate. This uses a modified version of `encode_df` (`encode_df_decim`) of `MorseGen` thus the original ratio in samples per dit is respected. This effectively takes a floating point ratio (shown in display) for the samples per dit decimation (about 5.77 for the nominal values of 8 kHz sampling rate and 13 WPM Morse code speed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MorseGen\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#phrase = '01234 6789 QUICK BROWN FOX 01234 6789 QUICK BROWN FOX01234 6789 QUICK BROWN FOX01234 6789 QUICK BROWN FOX01234 6789 QUICK BROWN FOX 01234 6789 QUICK BROWN FOX'\n",
    "#phrase = '7U7K 0DC55B H ZN0J Q9 H2X0 LZ16A ECA2DE 6A2 NUPU 67IL6EIH YVZA 5OTGC3U C3R PGW RS0 84QTV4PB EZ1 JBGJ TT1W4M5PBJ GZVLWXQG 7POU6 FMTXA N3CZ Y1Q9VZ6 9TVL CWP8KSB'\n",
    "phrase = '6 WREB W7UU QNWXS2 3KRO72Q AN1TI QZIWH G L0U7 Y17X45 OVIC2 C052W00PI60 O5Y 10R2N 4 FHC JXRGS4 DWBOL7ZUXJU EMNC3 WWBNT7 0UP GMKQ YG83H8 IT2Q Y0YBZ SQ80I5 W7SW 0K BMJ8JPM 51CK1 R08T 7SU1LYS7W6T 4JKVQF V3G UU2O1OM4 P4B 4A9DLC VI1H 4 HMP57 Q6G3 4QADIG FRJ 0MVL EPSM CS N9IZEMA GSRWUPBYB FD29 YI3PY N31W X88NS 773EW4Q4 LSW'\n",
    "Fs = 8000\n",
    "morse_gen = MorseGen.Morse()\n",
    "samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "n_prev = int((samples_per_dit/128)*12) + 1 # number of samples to look back is slightly more than a dit-dah and a word space (2+3+7=12)\n",
    "print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "label_df = morse_gen.encode_df_decim(phrase, samples_per_dit, 128)\n",
    "# keep just the envelope\n",
    "label_df.drop(columns=['dit','dah', 'ele', 'chr', 'wrd'], inplace=True)\n",
    "print(label_df.shape)\n",
    "plt.figure(figsize=(50,5))\n",
    "x = 0\n",
    "y = 1500\n",
    "plt.plot(label_df[x:y].env*0.9 + 0.0, label='env')\n",
    "plt.title(\"labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Envelope\n",
    "\n",
    "The SNR must be calculated in the FFT bin bandwidth. In the original `RNN-Morse-pytorch` notebook the bandwidth is 4 kHz / 256 = 15,625 Hz and SNR is 3 dB. Theoretically you would apply the FFT ratio to the original SNR but this does not work in practice. You have to take a much lower SNR to obtain a similar envelope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "SNR_dB = -25\n",
    "SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "SNR_linear *= 256 # Apply original FFT\n",
    "print(f'Resulting SNR for original {SNR_dB} dB is {(10.0 * np.log10(SNR_linear)):.2f} dB')\n",
    "t = np.linspace(0, len(label_df)-1, len(label_df))\n",
    "morsecode = label_df.env\n",
    "power = morsecode.var()\n",
    "noise_power = power/SNR_linear\n",
    "noise0 = np.sqrt(noise_power)*np.random.normal(0, 1, len(morsecode))\n",
    "noise1 = np.sqrt(noise_power)*np.random.normal(0, 1, len(morsecode))\n",
    "signal = morsecode + noise0\n",
    "print(len(signal))\n",
    "\n",
    "plt.figure(figsize=[25,5])\n",
    "plt.plot(signal[x:y] + 2.0, label='s+n0')\n",
    "plt.plot(noise0[x:y], label='n0')\n",
    "plt.plot(noise1[x:y], label='n1')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "\n",
    "Let's create the model now so we have an idea of its inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MorseEnvLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "    \n",
    "class MorseEnvLSTM2(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM stack\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=2, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(2, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(2, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "        \n",
    "class MorseEnvNoHLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Do not keep hidden cell\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1), (h0, c0))\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "class MorseEnvBiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Attempt Bidirectional LSTM: does not work\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_size=12, num_layers=1, num_classes=6):\n",
    "        super(MorseEnvBiLSTM, self).__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x.view(len(x), 1, -1), (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model instance and print the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers:\n",
    "# 4: good at reconstructing signal, some post-processing necessary for dit/dah, word silence is weak and undistinguishable from character silence \n",
    "# 5: fairly good at reconstructing signal, all signals distinguishable with some post-processing for dit/dah\n",
    "# 6: more contrast on all signals but a spike appears in the character space in predicted envelope\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "morse_env_model = MorseEnvLSTM(device, input_size=2, hidden_layer_size=6, output_size=1).to(device) # This is the only way to get things work properly with device\n",
    "morse_env_loss_function = nn.MSELoss()\n",
    "morse_env_optimizer = torch.optim.Adam(morse_env_model.parameters(), lr=0.001)\n",
    "\n",
    "print(morse_env_model)\n",
    "print(morse_env_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu\n",
    "for m in morse_env_model.parameters():\n",
    "    print(m.shape, m.device)\n",
    "X_t = torch.rand((12, 2))\n",
    "X_t = X_t.to(device)\n",
    "print(X_t)\n",
    "morse_env_model(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "channels=10\n",
    "H=n_prev\n",
    "W=1\n",
    "torchinfo.summary(morse_env_model, input_size=(channels, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training data\n",
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = signal.to_numpy()\n",
    "sig /= max(sig)\n",
    "labels = label_df\n",
    "labels = labels.truncate(after=len(sig)-1, copy=False)\n",
    "print(type(labels), labels.shape, type(sig), sig.shape, type(noise1), noise1.shape)\n",
    "plt.figure(figsize=[25,5])\n",
    "plt.plot(sig[x:y])\n",
    "plt.title(\"Signal (X0)\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(sig[x:y]*0.9 + 0.0, label=\"X0\")\n",
    "plt.plot(labels[x:y].env*0.9 + 1.0, label=\"env_y\")\n",
    "plt.title(\"image line and labels\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data for PyTorch \n",
    "With training and test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test values for splitting\n",
    "test_ratio = 0.5\n",
    "n_trn = round(len(labels) * (1 - test_ratio))\n",
    "print(n_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result are distinct tensors of input tensors and output tensors directly moved to device (GPU if this is the case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_rolling_window(x, window_size, step_size=1):\n",
    "    # unfold dimension to make our rolling window\n",
    "    return x.unfold(0, window_size, step_size).transpose(2,1)\n",
    "\n",
    "X = np.vstack((sig, noise1)).T\n",
    "X_train = pytorch_rolling_window(torch.FloatTensor(X[:n_trn]), n_prev, 1).to(device)\n",
    "y_train = torch.FloatTensor(labels.iloc[n_prev:n_trn+1].values).to(device)\n",
    "print(\"Train shapes\", X_train.shape, y_train.shape)\n",
    "print(\"X train\\n\", X_train)\n",
    "print(\"y_train\\n\", y_train)\n",
    "print(\"train[0] shapes\", X_train[0].shape, y_train[0].shape)\n",
    "X_test = pytorch_rolling_window(torch.FloatTensor(X[n_trn:-1]), n_prev, 1).to(device)\n",
    "y_test = torch.FloatTensor(labels.iloc[n_trn+n_prev:].values).to(device)\n",
    "print(\"Test shape\", X_test.shape, y_test.shape)\n",
    "# make sure it works\n",
    "y_pred = morse_env_model(X_train[0])\n",
    "print(\"y_pred\\n\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to CPU for visualization\n",
    "X_train_v = X_train.cpu()\n",
    "y_train_v = y_train.cpu()\n",
    "X_test_v = X_test.cpu()\n",
    "y_test_v = y_test.cpu()\n",
    "\n",
    "# Input (noisy) data for visualization\n",
    "l_train = sig[:n_trn+n_prev]\n",
    "l_test = sig[n_trn+n_prev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "b = []\n",
    "for t in range(5):\n",
    "    a.append(X_test_v[t*n_prev])\n",
    "    b.append(X_train_v[t*n_prev])\n",
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(np.concatenate((tuple(a)))*0.5, label='test')\n",
    "plt.plot(np.concatenate((tuple(b)))*0.5+0.5, label='train')\n",
    "plt.title(\"Train and test\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(5):\n",
    "    a.append(X_test_v[i*n_prev])\n",
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(np.concatenate(tuple(a)), label='X_test')\n",
    "plt.plot(l_test[:5*n_prev]+1.0, label='line')\n",
    "plt.plot(y_test_v[:5*n_prev,0]+2.0, label='y_test')\n",
    "plt.title(\"Test\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 2\n",
    "morse_env_model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    for j in range (len(X_train)):\n",
    "        morse_env_optimizer.zero_grad()\n",
    "        if morse_env_model.__class__.__name__ in [\"MorseEnvLSTM\", \"MorseEnvLSTM2\"]:\n",
    "            morse_env_model.zero_hidden_cell() # this model needs to reset the hidden cell\n",
    "        y_pred = morse_env_model(X_train[j])\n",
    "        single_loss = morse_env_loss_function(y_pred, y_train[j])\n",
    "        single_loss.backward()\n",
    "        morse_env_optimizer.step()\n",
    "        if j % 1000 == 0:\n",
    "            print(f'   train {j}/{len(X_train)} loss: {single_loss.item():10.8f}')\n",
    "    print(f'epoch: {i+1:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'final: {i+1:3} epochs loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(morse_env_model.state_dict(), 'models/morse_env_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_sig_l = []\n",
    "morse_env_model.eval()\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    with torch.no_grad():\n",
    "        pred_val = morse_env_model(X_test[i]).cpu()\n",
    "        p_sig_l.append(pred_val[0].item())\n",
    "        \n",
    "p_sig = np.array(p_sig_l)\n",
    "\n",
    "# trim negative values\n",
    "p_sig[p_sig < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,2))\n",
    "plt.plot(y_test_v[:y,0]*0.9, label=\"y0\")\n",
    "plt.plot(p_sig[:y]*0.9 + 1.0, label=\"sig\")\n",
    "plt.title(\"Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('img/pred.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = p_sig[:y]\n",
    "sig = (sig - min(sig)) / (max(sig) - min(sig))\n",
    "mor = y_test_v[:y,0]\n",
    "mor = (mor - min(mor)) / (max(mor) - min(mor))\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(sig, label=\"sig\")\n",
    "plt.plot(l_test[:y] + 1.0, label=\"inp\")\n",
    "plt.title(\"predicted signal modulation\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.special\n",
    "from scipy.io import wavfile\n",
    "\n",
    "Fcode = 600\n",
    "Fs = 8000\n",
    "noverlap = 128\n",
    "decim = 128\n",
    "emod = sig\n",
    "emod /= max(emod)\n",
    "remod = np.array([[x]*noverlap for x in emod]).flatten()\n",
    "mor = y_test_v[:y,0]\n",
    "mor = (mor - min(mor)) / (max(mor) - min(mor))\n",
    "ref_mod = np.array([[x]*decim for x in mor]).flatten()\n",
    "wt = (Fcode / Fs)*2*np.pi\n",
    "tone = np.sin(np.arange(len(remod))*wt)\n",
    "wavfile.write('audio/re.wav', Fs, tone*remod)\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.plot(tone*remod, label='mod')\n",
    "plt.plot(ref_mod*1.2, label='mor')\n",
    "plt.title(\"reconstructed signal\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omod = l_test[:y]\n",
    "omod / max(omod)\n",
    "orig_mod = np.array([[x]*decim for x in omod]).flatten()\n",
    "wavfile.write('audio/or.wav', Fs, tone*orig_mod)\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.plot(tone*orig_mod, label='ori')\n",
    "plt.plot(ref_mod*1.2, label='mor')\n",
    "plt.title(\"original filtered signal\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phrase = '6 WREB W7UU QNWXS2 3KRO72Q AN1TI QZIWH G L0U7 Y17X45 OVIC2 C052W00PI60 O5Y 10R2N 4 FHC JXRGS4 DWBOL7ZUXJU EMNC3 WWBNT7 0UP GMKQ YG83H8 IT2Q Y0YBZ SQ80I5 W7SW 0K BMJ8JPM 51CK1 R08T 7SU1LYS7W6T 4JKVQF V3G UU2O1OM4 P4B 4A9DLC VI1H 4 HMP57 Q6G3 4QADIG FRJ 0MVL EPSM CS N9IZEMA GSRWUPBYB FD29 YI3PY N31W X88NS 773EW4Q4 LSW'\n",
    "phrase = 'VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV D'\n",
    "Fs = 8000\n",
    "morse_gen = MorseGen.Morse()\n",
    "samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "n_prev = int((samples_per_dit/128)*12) + 1 # number of samples to look back is slightly more than a dit-dah and a word space (2+3+7=12)\n",
    "print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "label_df = morse_gen.encode_df_decim(phrase, samples_per_dit, 128)\n",
    "# keep just the envelope\n",
    "label_df.drop(columns=['dit','dah', 'ele', 'chr', 'wrd'], inplace=True)\n",
    "print(label_df.shape)\n",
    "plt.figure(figsize=(50,5))\n",
    "x = 0\n",
    "y = 1500\n",
    "plt.plot(label_df[x:y].env*0.9 + 0.0, label='env')\n",
    "plt.title(\"labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_dB = -20\n",
    "SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "SNR_linear *= 256 # Apply original FFT\n",
    "print(f'Resulting SNR for original {SNR_dB} dB is {(10.0 * np.log10(SNR_linear)):.2f} dB')\n",
    "t = np.linspace(0, len(label_df)-1, len(label_df))\n",
    "morsecode = label_df.env\n",
    "power = morsecode.var()\n",
    "noise_power = power/SNR_linear\n",
    "noise0 = np.sqrt(noise_power)*np.random.normal(0, 1, len(morsecode))\n",
    "noise1 = np.sqrt(noise_power)*np.random.normal(0, 1, len(morsecode))\n",
    "signal = morsecode + noise0\n",
    "print(len(signal))\n",
    "\n",
    "plt.figure(figsize=[25,5])\n",
    "plt.plot(signal[x:y] + 2.0, label='s+n0')\n",
    "plt.plot(noise0[x:y], label='n0')\n",
    "plt.plot(noise1[x:y], label='n1')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training data (new prediction)\n",
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = signal.to_numpy()\n",
    "sig /= max(sig)\n",
    "labels = label_df\n",
    "labels = labels.truncate(after=len(sig)-1, copy=False)\n",
    "print(type(labels), type(sig), labels.shape, sig.shape, len(labels), len(sig))\n",
    "plt.figure(figsize=[25,5])\n",
    "plt.plot(sig[x:y])\n",
    "plt.title(\"Signal (X)\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,2))\n",
    "plt.plot(sig[x:y]*0.9 + 0.0, label=\"sig_X\")\n",
    "plt.plot(labels[x:y].env*0.9 + 1.0, label=\"env_y\")\n",
    "plt.title(\"image line and labels\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format new data for PyTorch \n",
    "New X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((sig, noise1)).T\n",
    "X_train = pytorch_rolling_window(torch.FloatTensor(X[:n_trn]), n_prev, 1).to(device)\n",
    "y_train = torch.FloatTensor(labels.iloc[n_prev:n_trn+1].values).to(device)\n",
    "X_test = pytorch_rolling_window(torch.FloatTensor(X[n_trn:-1]), n_prev, 1).to(device)\n",
    "y_test = torch.FloatTensor(labels.iloc[n_trn+n_prev:].values).to(device)\n",
    "# make sure it works\n",
    "y_pred = morse_env_model(X_train[0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to CPU for visualization\n",
    "X_train_v = X_train.cpu()\n",
    "y_train_v = y_train.cpu()\n",
    "X_test_v = X_test.cpu()\n",
    "y_test_v = y_test.cpu()\n",
    "\n",
    "# Input (noisy) data for visualization\n",
    "l_train = sig[:n_trn+n_prev]\n",
    "l_test = sig[n_trn+n_prev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "b = []\n",
    "for t in range(5):\n",
    "    a.append(X_test_v[t*n_prev])\n",
    "    b.append(X_train_v[t*n_prev])\n",
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(np.concatenate((tuple(a)))*0.5, label='test')\n",
    "plt.plot(np.concatenate((tuple(b)))*0.5+0.5, label='train')\n",
    "plt.title(\"Train and test\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(5):\n",
    "    a.append(X_test_v[i*n_prev])\n",
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(np.concatenate(tuple(a)), label='X_test')\n",
    "plt.plot(l_test[:5*n_prev]+1.0, label='line')\n",
    "plt.plot(y_test_v[:5*n_prev,0]+2.0, label='y_test')\n",
    "plt.title(\"Test\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict (new data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_sig_l = []\n",
    "morse_env_model.eval()\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    with torch.no_grad():\n",
    "        pred_val = morse_env_model(X_test[i]).cpu()\n",
    "        p_sig_l.append(pred_val[0].item())\n",
    "        \n",
    "p_sig = np.array(p_sig_l)\n",
    "\n",
    "# trim negative values\n",
    "p_sig[p_sig < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,2))\n",
    "plt.plot(y_test_v[:y,0]*0.9, label=\"mor\")\n",
    "plt.plot(p_sig[:y]*0.9 + 1.0, label=\"sig\")\n",
    "plt.title(\"Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = p_sig[:y]\n",
    "sig = (sig - min(sig)) / (max(sig) - min(sig))\n",
    "mor = y_test_v[:y,0]\n",
    "mor = (mor - min(mor)) / (max(mor) - min(mor))\n",
    "plt.figure(figsize=(30,6))\n",
    "plt.plot(sig, label=\"sig\")\n",
    "plt.plot(mor*1.2, label=\"mor\")\n",
    "plt.title(\"predicted signal modulation\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "#omod = np.array([sp.special.expit(12*(x-0.3)) for x in l_test[:y]])\n",
    "#omod = np.array([sp.special.expit(20*(x-0.18)) for x in l_test[:y]])\n",
    "omod = l_test[:y]\n",
    "orig_mod = np.array([[x]*decim for x in omod]).flatten()\n",
    "orig_mod /= max(orig_mod)\n",
    "wt = (Fcode / Fs)*2*np.pi\n",
    "tone = np.sin(np.arange(len(orig_mod))*wt)\n",
    "wavfile.write('audio/or1.wav', Fs, tone*orig_mod)\n",
    "ref_mod = np.array([[x]*decim for x in mor]).flatten()\n",
    "plt.figure(figsize=(50,5))\n",
    "plt.plot(tone*orig_mod, label='mod')\n",
    "plt.plot(ref_mod*1.2, label='mor')\n",
    "plt.title(\"original filtered signal\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "# def modscale(x):\n",
    "#     return sp.special.expit(20*(x-0.28))\n",
    "    \n",
    "#emod = np.array([sp.special.expit(40*(x-0.38)) for x in sig])\n",
    "emod = sig\n",
    "emod /= max(emod)\n",
    "#emod = modn\n",
    "remod = np.array([[x]*decim for x in emod]).flatten()\n",
    "remor = np.array([[x]*decim for x in mor]).flatten()\n",
    "wt = (Fcode / Fs)*2*np.pi\n",
    "tone = np.sin(np.arange(len(remod))*wt)\n",
    "wavfile.write('audio/re1.wav', Fs, tone*remod)\n",
    "plt.figure(figsize=(50,5))\n",
    "plt.plot(tone*remod, label='filt')\n",
    "plt.plot(remor*1.2, label='omod')\n",
    "plt.title(\"reconstructed signal\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.linspace(0, 1, 100)\n",
    "ys = np.array([sp.special.expit(40*(x-0.38)) for x in xs])\n",
    "plt.figure(figsize=(30,6))\n",
    "plt.plot(ys, label=\"sig\")\n",
    "plt.title(\"modified sigmoid\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
